name: Daily Stock News Modeling

on:
  schedule:
    - cron: '0 2 * * *'  # Runs daily at 2:00 AM UTC = 7:00 PM PDT
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install jupyter nbconvert pandas openpyxl scikit-learn xgboost matplotlib seaborn nltk transformers textblob nrclex yfinance pytz newsdataapi

      - name: Export API Key to environment
        run: echo "NEWSDATA_API_KEY=${{ secrets.NEWSDATA_API_KEY }}" >> $GITHUB_ENV

      - name: Download NLTK and TextBlob corpora
        run: |
          python -m nltk.downloader punkt vader_lexicon averaged_perceptron_tagger wordnet
          python -m textblob.download_corpora

      - name: Run Master Notebook
        run: |
          jupyter nbconvert --to notebook --execute "notebooks/Master_Data_Modeling.ipynb" --output "Master_Data_Modeling_output.ipynb" --output-dir notebooks

